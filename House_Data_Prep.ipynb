{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO9FEfFt7RwF"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzXruhb47RiN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WaclQKQn7ALF"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "nEE8P-UV6xcP",
    "outputId": "194005e1-e857-4515-a915-f50bc58f414a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "p0jGezKu8i2q",
    "outputId": "7e9f7882-57f0-41cf-bfa8-b3073047ff3a"
   },
   "outputs": [],
   "source": [
    "#os.listdir(\"/content/drive/My Drive/Colab Notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "pf77Pfp0S_He",
    "outputId": "2f5c2b03-1bb6-44c9-eecd-4da28bc13705"
   },
   "outputs": [],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iY7F2VQ894v"
   },
   "outputs": [],
   "source": [
    "housePath = \"/content/drive/My Drive/Colab Notebooks/house_prices.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnHL_uq170kW"
   },
   "source": [
    "# Load excel data for House Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7LS7YdF65F3"
   },
   "outputs": [],
   "source": [
    "# #wb = xlrd.open_workbook(housePath)\n",
    "# #data = pd.read_excel(housePath)\n",
    "# xl = pd.ExcelFile(housePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBWSxvhkL7YT"
   },
   "source": [
    "### Extract sheets, concat sheets, and pickle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2CTI56R_rjh"
   },
   "outputs": [],
   "source": [
    "# df00 = xl.parse(\"2000\")\n",
    "# df01 = xl.parse(\"2001\")\n",
    "# df02 = xl.parse(\"2002\")\n",
    "# df03 = xl.parse(\"2003\")\n",
    "# df04 = xl.parse(\"2004\")\n",
    "# df05 = xl.parse(\"2005\")\n",
    "# df06 = xl.parse(\"2006\")\n",
    "# df07 = xl.parse(\"2007\")\n",
    "# df08 = xl.parse(\"2008\")\n",
    "# df09 = xl.parse(\"2009\")\n",
    "# df10 = xl.parse(\"2010\")\n",
    "# df11 = xl.parse(\"2011\")\n",
    "# df12 = xl.parse(\"2012\")\n",
    "# df13 = xl.parse(\"2013\")\n",
    "# df14 = xl.parse(\"2014\")\n",
    "# df15 = xl.parse(\"2015\")\n",
    "# df16 = xl.parse(\"2016\")\n",
    "# df17 = xl.parse(\"2017\")\n",
    "# df18 = xl.parse(\"2018\")\n",
    "# df19 = xl.parse(\"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3aG-HD_It6o"
   },
   "outputs": [],
   "source": [
    "# df00.to_pickle(\"df00.pkl\")\n",
    "# df01.to_pickle(\"df01.pkl\")\n",
    "# df02.to_pickle(\"df02.pkl\")\n",
    "# df03.to_pickle(\"df03.pkl\")\n",
    "# df04.to_pickle(\"df04.pkl\")\n",
    "# df05.to_pickle(\"df05.pkl\")\n",
    "# df06.to_pickle(\"df06.pkl\")\n",
    "# df07.to_pickle(\"df07.pkl\")\n",
    "# df08.to_pickle(\"df08.pkl\")\n",
    "# df09.to_pickle(\"df09.pkl\")\n",
    "# df10.to_pickle(\"df10.pkl\")\n",
    "# df11.to_pickle(\"df11.pkl\")\n",
    "# df12.to_pickle(\"df12.pkl\")\n",
    "# df13.to_pickle(\"df13.pkl\")\n",
    "# df14.to_pickle(\"df14.pkl\")\n",
    "# df15.to_pickle(\"df15.pkl\")\n",
    "# df16.to_pickle(\"df16.pkl\")\n",
    "# df17.to_pickle(\"df17.pkl\")\n",
    "# df18.to_pickle(\"df18.pkl\")\n",
    "# df19.to_pickle(\"df19.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00 = pd.read_pickle(\"./Pickle/df00.pkl\")\n",
    "df01 = pd.read_pickle(\"./Pickle/df01.pkl\")\n",
    "df02 = pd.read_pickle(\"./Pickle/df02.pkl\")\n",
    "df03 = pd.read_pickle(\"./Pickle/df03.pkl\")\n",
    "df04 = pd.read_pickle(\"./Pickle/df04.pkl\")\n",
    "df05 = pd.read_pickle(\"./Pickle/df05.pkl\")\n",
    "df06 = pd.read_pickle(\"./Pickle/df06.pkl\")\n",
    "df07 = pd.read_pickle(\"./Pickle/df07.pkl\")\n",
    "df08 = pd.read_pickle(\"./Pickle/df08.pkl\")\n",
    "df09 = pd.read_pickle(\"./Pickle/df09.pkl\")\n",
    "df10 = pd.read_pickle(\"./Pickle/df10.pkl\")\n",
    "df11 = pd.read_pickle(\"./Pickle/df11.pkl\")\n",
    "df12 = pd.read_pickle(\"./Pickle/df12.pkl\")\n",
    "df13 = pd.read_pickle(\"./Pickle/df13.pkl\")\n",
    "df14 = pd.read_pickle(\"./Pickle/df14.pkl\")\n",
    "df15 = pd.read_pickle(\"./Pickle/df15.pkl\")\n",
    "df16 = pd.read_pickle(\"./Pickle/df16.pkl\")\n",
    "df17 = pd.read_pickle(\"./Pickle/df17.pkl\")\n",
    "df18 = pd.read_pickle(\"./Pickle/df18.pkl\")\n",
    "df19 = pd.read_pickle(\"./Pickle/df19.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = [df00,df01,df02,df03,df04,df05,df06,\n",
    "         df07,df08,df09,df10,df11,df12,df13,\n",
    "         df14,df15,df16,df17,df18,df19]\n",
    "\n",
    "rawHouse = pd.concat(dfList)\n",
    "rawHouse.to_pickle('rawHouse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawHouse.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean house from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = pd.read_pickle('rawHouse.pkl')\n",
    "\n",
    "colList = ['PARCEL','GARAGE 1 TYPE','GARAGE 2 TYPE']\n",
    "\n",
    "house['Age'] = house['YEAR'] - house['YR BUILT']\n",
    "\n",
    "house['YEAR'] = house['YEAR'].astype(str)\n",
    "house['YEAR'] = house['YEAR'].astype('datetime64[Y]')\n",
    "\n",
    "\n",
    "for col in colList:\n",
    "    house[col] = house[col].astype('category')\n",
    "\n",
    "house.iloc[:,4:14] = house.iloc[:,4:14].astype('category')\n",
    "\n",
    "# Remove houses that have TAV = $0 and only single family dwellings\n",
    "house = house.loc[house['TAV'] != 0]\n",
    "house = house.loc[house['DWELLINGS'].str.contains('SFD')]\n",
    "\n",
    "house = house.drop(['SUFFIX', 'DWELLINGS'], axis = 1)\n",
    "\n",
    "\n",
    "house.to_pickle('house.pkl')\n",
    "#house.head(5)\n",
    "house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(house.dtypes)\n",
    "#house.head(5)\n",
    "#house.iloc[15:20,:]\n",
    "#house.SUFFIX.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.DWELLINGS.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for 1st source of neighborhood data. Being replaced with Group_List.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " xlG = pd.ExcelFile('./Data/GROUP_LIST.xlsx')\n",
    "groupList = xlG.parse('GROUP')\n",
    "\n",
    "groupList.to_pickle('groupList.pkl')\n",
    "groupList.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join groupList.pkl to house.pkl, to make houseAll.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupList = pd.read_pickle('groupList.pkl')\n",
    "house = pd.read_pickle('house.pkl')\n",
    "\n",
    "houseAll = pd.merge(house, groupList, on = 'GROUP', how = 'left')\n",
    "\n",
    "colList = ['GROUP', 'GEO-ECONOMIC AREA', 'MLS AREA']\n",
    "\n",
    "for col in colList:\n",
    "    houseAll[col] = houseAll[col].astype('category')\n",
    "    \n",
    "houseAll = houseAll[houseAll['YEAR'] != '2019-01-01']    \n",
    "\n",
    "houseAll = houseAll.rename(columns={'GEO-ECONOMIC AREA' : 'Neighborhood','MLS AREA' : 'Area',\n",
    "                                    'YEAR' : 'Year', 'TOTAL SQ FT' : 'Total_Sq_Ft',\n",
    "                                    'YR BUILT' : 'Year_Built', 'BEDROOMS' : 'Bedroom_Count',\n",
    "                                   'PARCEL' : 'Parcel', 'GROUP' : 'Group', 'BATHROOMS' : 'Bathroom_Count'})\n",
    "\n",
    "houseAll.to_pickle('houseAll.pkl')\n",
    "houseAll.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseAll.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find % change in TAV from prev year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delightb\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parcel</th>\n",
       "      <th>Year</th>\n",
       "      <th>Group</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Area</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bedroom_Count</th>\n",
       "      <th>Bathroom_Count</th>\n",
       "      <th>TAV</th>\n",
       "      <th>TAV_Ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0017650020</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>NORTH CENTRAL BENCH</td>\n",
       "      <td>W BOISE</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0017650030</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>NORTH CENTRAL BENCH</td>\n",
       "      <td>W BOISE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0017650040</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>NORTH CENTRAL BENCH</td>\n",
       "      <td>W BOISE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0017650050</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>NORTH CENTRAL BENCH</td>\n",
       "      <td>W BOISE</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>ABBS SUB</td>\n",
       "      <td>CENTRAL BOISE BENCH</td>\n",
       "      <td>BOISE BENCH</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>129100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Parcel       Year           Group         Neighborhood         Area  \\\n",
       "0  R0017650020 2000-01-01  AARON PARK SUB  NORTH CENTRAL BENCH      W BOISE   \n",
       "1  R0017650030 2000-01-01  AARON PARK SUB  NORTH CENTRAL BENCH      W BOISE   \n",
       "2  R0017650040 2000-01-01  AARON PARK SUB  NORTH CENTRAL BENCH      W BOISE   \n",
       "3  R0017650050 2000-01-01  AARON PARK SUB  NORTH CENTRAL BENCH      W BOISE   \n",
       "4  R0027000008 2000-01-01        ABBS SUB  CENTRAL BOISE BENCH  BOISE BENCH   \n",
       "\n",
       "   Age  Bedroom_Count  Bathroom_Count       TAV  TAV_Ch  \n",
       "0    2              4            4.00  158000.0     NaN  \n",
       "1    1              4            4.00  165800.0     NaN  \n",
       "2    1              4            4.00  165800.0     NaN  \n",
       "3    2              4            4.00  155000.0     NaN  \n",
       "4   63              1            1.25  129100.0     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houseAll = pd.read_pickle('houseAll.pkl')\n",
    "\n",
    "df = houseAll[['Parcel','Year','Group', 'Neighborhood','Area', 'Age','Bedroom_Count','Bathroom_Count','TAV']]\n",
    "\n",
    "df['TAV_Ch'] = df.groupby('Parcel')['TAV'].pct_change()\n",
    "\n",
    "df.to_pickle('abvHouse.pkl')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parcel</th>\n",
       "      <th>Year</th>\n",
       "      <th>TAV</th>\n",
       "      <th>TAV_Ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>129100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54677</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>145600.0</td>\n",
       "      <td>0.127808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110200</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>146700.0</td>\n",
       "      <td>0.007555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166351</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>161700.0</td>\n",
       "      <td>0.102249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223313</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>165200.0</td>\n",
       "      <td>0.021645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281777</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>175500.0</td>\n",
       "      <td>0.062349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343520</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>225800.0</td>\n",
       "      <td>0.286610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405877</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>237600.0</td>\n",
       "      <td>0.052259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468969</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>237600.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532710</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>175900.0</td>\n",
       "      <td>-0.259680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597119</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>155200.0</td>\n",
       "      <td>-0.117681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661869</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>146600.0</td>\n",
       "      <td>-0.055412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727108</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>147700.0</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792898</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>173400.0</td>\n",
       "      <td>0.174001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859137</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>194400.0</td>\n",
       "      <td>0.121107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925857</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>205800.0</td>\n",
       "      <td>0.058642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993664</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>219500.0</td>\n",
       "      <td>0.066569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062135</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>248100.0</td>\n",
       "      <td>0.130296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131274</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>307100.0</td>\n",
       "      <td>0.237807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Parcel       Year       TAV    TAV_Ch\n",
       "4        R0027000008 2000-01-01  129100.0       NaN\n",
       "54677    R0027000008 2001-01-01  145600.0  0.127808\n",
       "110200   R0027000008 2002-01-01  146700.0  0.007555\n",
       "166351   R0027000008 2003-01-01  161700.0  0.102249\n",
       "223313   R0027000008 2004-01-01  165200.0  0.021645\n",
       "281777   R0027000008 2005-01-01  175500.0  0.062349\n",
       "343520   R0027000008 2006-01-01  225800.0  0.286610\n",
       "405877   R0027000008 2007-01-01  237600.0  0.052259\n",
       "468969   R0027000008 2008-01-01  237600.0  0.000000\n",
       "532710   R0027000008 2009-01-01  175900.0 -0.259680\n",
       "597119   R0027000008 2010-01-01  155200.0 -0.117681\n",
       "661869   R0027000008 2011-01-01  146600.0 -0.055412\n",
       "727108   R0027000008 2012-01-01  147700.0  0.007503\n",
       "792898   R0027000008 2013-01-01  173400.0  0.174001\n",
       "859137   R0027000008 2014-01-01  194400.0  0.121107\n",
       "925857   R0027000008 2015-01-01  205800.0  0.058642\n",
       "993664   R0027000008 2016-01-01  219500.0  0.066569\n",
       "1062135  R0027000008 2017-01-01  248100.0  0.130296\n",
       "1131274  R0027000008 2018-01-01  307100.0  0.237807"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcelNum = 'R2024320455'\n",
    "x = pd.read_pickle('abvHouse.pkl')\n",
    "x = x[x['Parcel'] == 'R0027000008']\n",
    "x = x[['Parcel','Year','TAV','TAV_Ch']]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
