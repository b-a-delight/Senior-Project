{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "path = 'C:/Users/delightb/Desktop/Final_Project/Senior-Project/Pickle'\n",
    "####   = pd.read_pickle(os.path.join(path,'abvHouse.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.listendata.com/2018/01/linear-regression-in-python.html#Calculate-R-Squared-and-Adjusted-R-Squared-Manually-on-Test-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data split into dependent and independent variables already figured out in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(path,'oneHotEncode.pkl'))\n",
    "df = df.drop(columns = ['Year'])\n",
    "#df = clean_dataset(df)\n",
    "\n",
    "lm_df = df.copy()\n",
    "\n",
    "feature_cols = df.columns.get_values()\n",
    "feature_cols = feature_cols.tolist()\n",
    "feature_cols.remove('TAV_Ch')\n",
    "feature_cols.remove('TAV')\n",
    "\n",
    "\n",
    "y = lm_df.TAV_Ch\n",
    "x = lm_df[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and test sets\n",
    "Using sklearn we split 80% of our data into training set and rest in test set. Setting random_state will give the same training and test set everytime on running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running linear regression using sklearn\n",
    "Using sklearn linear regression can be carried out using LinearRegression( ) class. sklearn automatically adds an intercept term to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm = lm.fit(x_train,y_train)   #lm.fit(input,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store coefficients in a data frame along with their respective independent variables -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(lm.coef_))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict the values of y on the test set we use lm.predict( )\n",
    "### Errors are the difference between observed and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(x_test)\n",
    "y_error = y_test - y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R square can be obbtained using sklearn.metrics ( ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running linear regression using statsmodels\n",
    "It is to be noted that statsmodels does not add intercept term automatically thus we need to create an intercept to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delightb\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorenviron\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sma\n",
    "X_train = sma.add_constant(x_train) ## let's add an intercept (beta_0) to our model\n",
    "X_test = sma.add_constant(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression can be run by using sm.OLS:\n",
    "updated the module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.formula.api as sm\n",
    "import statsmodels.regression.linear_model as sm\n",
    "\n",
    "lm2 = sm.OLS(y_train,X_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of our model can be obtained via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>TAV_Ch</td>      <th>  R-squared:         </th>  <td>   0.677</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.677</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.703e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Sep 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:46:43</td>     <th>  Log-Likelihood:    </th> <td>1.2715e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>841657</td>      <th>  AIC:               </th> <td>-2.543e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>841625</td>      <th>  BIC:               </th> <td>-2.542e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                               <td></td>                                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                                      <td>    0.0096</td> <td>    0.000</td> <td>   22.274</td> <td> 0.000</td> <td>    0.009</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                                                        <td>    0.0002</td> <td> 3.11e-06</td> <td>   62.991</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bedroom_Count</th>                                              <td>-9.046e-06</td> <td> 7.56e-05</td> <td>   -0.120</td> <td> 0.905</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bathroom_Count</th>                                             <td>   -0.0016</td> <td>    0.000</td> <td>  -16.046</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Architecture And Engineering Occupations</th>                   <td>   -0.0585</td> <td>    0.001</td> <td>  -57.454</td> <td> 0.000</td> <td>   -0.060</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Arts, Design, Entertainment, Sports, And Media Occupations</th> <td>    0.2557</td> <td>    0.001</td> <td>  359.915</td> <td> 0.000</td> <td>    0.254</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Building And Grounds Cleaning And Maintenance Occupations</th>  <td>    0.1021</td> <td>    0.001</td> <td>  177.176</td> <td> 0.000</td> <td>    0.101</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Business And Financial Operations Occupations</th>              <td>   -0.1259</td> <td>    0.001</td> <td> -205.431</td> <td> 0.000</td> <td>   -0.127</td> <td>   -0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Community And Social Service Occupations</th>                   <td>    0.0047</td> <td>    0.001</td> <td>    7.856</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Computer And Mathematical Occupations</th>                      <td>    0.0727</td> <td>    0.001</td> <td>   58.037</td> <td> 0.000</td> <td>    0.070</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Construction And Extraction Occupations</th>                    <td>    0.0317</td> <td>    0.000</td> <td>   90.351</td> <td> 0.000</td> <td>    0.031</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education, Training, And Library Occupations</th>               <td>   -0.1673</td> <td>    0.001</td> <td> -239.146</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Farming, Fishing, And Forestry Occupations</th>                 <td>    0.0614</td> <td>    0.001</td> <td>  118.116</td> <td> 0.000</td> <td>    0.060</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Food Preparation And Serving Related Occupations</th>           <td>   -0.0706</td> <td>    0.001</td> <td>  -82.329</td> <td> 0.000</td> <td>   -0.072</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Healthcare Practitioner And Technical Occupations</th>          <td>    0.2392</td> <td>    0.001</td> <td>  270.996</td> <td> 0.000</td> <td>    0.237</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Healthcare Support Occupations</th>                             <td>    0.0607</td> <td>    0.001</td> <td>   58.062</td> <td> 0.000</td> <td>    0.059</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Installation, Maintenance, And Repair Occupations</th>          <td>    0.1261</td> <td>    0.000</td> <td>  414.121</td> <td> 0.000</td> <td>    0.125</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legal Occupations</th>                                          <td>   -0.0176</td> <td>    0.001</td> <td>  -25.200</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Life, Physical, And Social Science Occupations</th>             <td>   -0.1557</td> <td>    0.001</td> <td> -219.483</td> <td> 0.000</td> <td>   -0.157</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Management Occupations</th>                                     <td>    0.4376</td> <td>    0.001</td> <td>  321.166</td> <td> 0.000</td> <td>    0.435</td> <td>    0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Office And Administrative Support Occupations</th>              <td>    0.0920</td> <td>    0.001</td> <td>  162.740</td> <td> 0.000</td> <td>    0.091</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Personal Care And Service Occupations</th>                      <td>   -0.0025</td> <td>    0.001</td> <td>   -4.052</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Production Occupations</th>                                     <td>    0.2681</td> <td>    0.001</td> <td>  517.176</td> <td> 0.000</td> <td>    0.267</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Protective Service Occupations</th>                             <td>   -0.0725</td> <td>    0.000</td> <td> -159.823</td> <td> 0.000</td> <td>   -0.073</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sales And Related Occupations</th>                              <td>    0.0623</td> <td>    0.001</td> <td>   52.418</td> <td> 0.000</td> <td>    0.060</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Transportation And Material Moving Occupations</th>             <td>    0.1385</td> <td>    0.001</td> <td>  130.956</td> <td> 0.000</td> <td>    0.136</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(10000.0, 40000.0]</th>                                         <td>   -0.1297</td> <td>    0.001</td> <td> -153.184</td> <td> 0.000</td> <td>   -0.131</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(40000.0, 70000.0]</th>                                         <td>   -0.0500</td> <td>    0.001</td> <td>  -58.550</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(70000.0, 100000.0]</th>                                        <td>    0.0184</td> <td>    0.000</td> <td>   75.024</td> <td> 0.000</td> <td>    0.018</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(100000.0, 150000.0]</th>                                       <td>   -0.0151</td> <td>    0.000</td> <td>  -69.283</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(150000.0, 200000.0]</th>                                       <td>   -0.0077</td> <td>    0.000</td> <td>  -36.743</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>(200000.0, 300000.0]</th>                                       <td>    0.0065</td> <td>    0.000</td> <td>   47.523</td> <td> 0.000</td> <td>    0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_House_Change</th>                                         <td>    0.1220</td> <td>    0.001</td> <td>  196.357</td> <td> 0.000</td> <td>    0.121</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_Pop_Change</th>                                           <td>    0.0653</td> <td>    0.000</td> <td>  202.986</td> <td> 0.000</td> <td>    0.065</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total_Emp_Change</th>                                           <td>    0.0679</td> <td>    0.000</td> <td>  358.231</td> <td> 0.000</td> <td>    0.067</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_BOISE BENCH</th>                                           <td>    0.0045</td> <td>    0.000</td> <td>   12.568</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_EAGLE</th>                                                 <td>   -0.0075</td> <td>    0.004</td> <td>   -1.943</td> <td> 0.052</td> <td>   -0.015</td> <td> 6.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_GARDEN CITY</th>                                           <td>   -0.0023</td> <td>    0.001</td> <td>   -3.314</td> <td> 0.001</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_NE BOISE</th>                                              <td>    0.0074</td> <td>    0.000</td> <td>   18.021</td> <td> 0.000</td> <td>    0.007</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_NE MERIDIAN</th>                                           <td>   -0.0035</td> <td>    0.001</td> <td>   -6.666</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_NORTH BOISE</th>                                           <td>    0.0070</td> <td>    0.000</td> <td>   18.732</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_NW BOISE-GARDEN CITY</th>                                  <td>    0.0019</td> <td>    0.000</td> <td>    4.968</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_SE BOISE</th>                                              <td>    0.0029</td> <td>    0.000</td> <td>    8.055</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_SW BOISE</th>                                              <td>   -0.0003</td> <td>    0.000</td> <td>   -0.698</td> <td> 0.485</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_SW BOISE-MERIDIAN</th>                                     <td> 7.013e-05</td> <td>    0.001</td> <td>    0.126</td> <td> 0.899</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_W BOISE</th>                                               <td>    0.0012</td> <td>    0.000</td> <td>    3.360</td> <td> 0.001</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Area_W BOISE-MERIDIAN</th>                                      <td>   -0.0018</td> <td>    0.000</td> <td>   -5.046</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>52329.014</td> <th>  Durbin-Watson:     </th>  <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>129580.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.376</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.769</td>   <th>  Cond. No.          </th>  <td>1.21e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.09e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 TAV_Ch   R-squared:                       0.677\n",
       "Model:                            OLS   Adj. R-squared:                  0.677\n",
       "Method:                 Least Squares   F-statistic:                 5.703e+04\n",
       "Date:                Fri, 20 Sep 2019   Prob (F-statistic):               0.00\n",
       "Time:                        14:46:43   Log-Likelihood:             1.2715e+06\n",
       "No. Observations:              841657   AIC:                        -2.543e+06\n",
       "Df Residuals:                  841625   BIC:                        -2.542e+06\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================================================\n",
       "                                                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------\n",
       "const                                                          0.0096      0.000     22.274      0.000       0.009       0.010\n",
       "Age                                                            0.0002   3.11e-06     62.991      0.000       0.000       0.000\n",
       "Bedroom_Count                                              -9.046e-06   7.56e-05     -0.120      0.905      -0.000       0.000\n",
       "Bathroom_Count                                                -0.0016      0.000    -16.046      0.000      -0.002      -0.001\n",
       "Architecture And Engineering Occupations                      -0.0585      0.001    -57.454      0.000      -0.060      -0.056\n",
       "Arts, Design, Entertainment, Sports, And Media Occupations     0.2557      0.001    359.915      0.000       0.254       0.257\n",
       "Building And Grounds Cleaning And Maintenance Occupations      0.1021      0.001    177.176      0.000       0.101       0.103\n",
       "Business And Financial Operations Occupations                 -0.1259      0.001   -205.431      0.000      -0.127      -0.125\n",
       "Community And Social Service Occupations                       0.0047      0.001      7.856      0.000       0.004       0.006\n",
       "Computer And Mathematical Occupations                          0.0727      0.001     58.037      0.000       0.070       0.075\n",
       "Construction And Extraction Occupations                        0.0317      0.000     90.351      0.000       0.031       0.032\n",
       "Education, Training, And Library Occupations                  -0.1673      0.001   -239.146      0.000      -0.169      -0.166\n",
       "Farming, Fishing, And Forestry Occupations                     0.0614      0.001    118.116      0.000       0.060       0.062\n",
       "Food Preparation And Serving Related Occupations              -0.0706      0.001    -82.329      0.000      -0.072      -0.069\n",
       "Healthcare Practitioner And Technical Occupations              0.2392      0.001    270.996      0.000       0.237       0.241\n",
       "Healthcare Support Occupations                                 0.0607      0.001     58.062      0.000       0.059       0.063\n",
       "Installation, Maintenance, And Repair Occupations              0.1261      0.000    414.121      0.000       0.125       0.127\n",
       "Legal Occupations                                             -0.0176      0.001    -25.200      0.000      -0.019      -0.016\n",
       "Life, Physical, And Social Science Occupations                -0.1557      0.001   -219.483      0.000      -0.157      -0.154\n",
       "Management Occupations                                         0.4376      0.001    321.166      0.000       0.435       0.440\n",
       "Office And Administrative Support Occupations                  0.0920      0.001    162.740      0.000       0.091       0.093\n",
       "Personal Care And Service Occupations                         -0.0025      0.001     -4.052      0.000      -0.004      -0.001\n",
       "Production Occupations                                         0.2681      0.001    517.176      0.000       0.267       0.269\n",
       "Protective Service Occupations                                -0.0725      0.000   -159.823      0.000      -0.073      -0.072\n",
       "Sales And Related Occupations                                  0.0623      0.001     52.418      0.000       0.060       0.065\n",
       "Transportation And Material Moving Occupations                 0.1385      0.001    130.956      0.000       0.136       0.141\n",
       "(10000.0, 40000.0]                                            -0.1297      0.001   -153.184      0.000      -0.131      -0.128\n",
       "(40000.0, 70000.0]                                            -0.0500      0.001    -58.550      0.000      -0.052      -0.048\n",
       "(70000.0, 100000.0]                                            0.0184      0.000     75.024      0.000       0.018       0.019\n",
       "(100000.0, 150000.0]                                          -0.0151      0.000    -69.283      0.000      -0.016      -0.015\n",
       "(150000.0, 200000.0]                                          -0.0077      0.000    -36.743      0.000      -0.008      -0.007\n",
       "(200000.0, 300000.0]                                           0.0065      0.000     47.523      0.000       0.006       0.007\n",
       "Total_House_Change                                             0.1220      0.001    196.357      0.000       0.121       0.123\n",
       "Total_Pop_Change                                               0.0653      0.000    202.986      0.000       0.065       0.066\n",
       "Total_Emp_Change                                               0.0679      0.000    358.231      0.000       0.067       0.068\n",
       "Area_BOISE BENCH                                               0.0045      0.000     12.568      0.000       0.004       0.005\n",
       "Area_EAGLE                                                    -0.0075      0.004     -1.943      0.052      -0.015    6.47e-05\n",
       "Area_GARDEN CITY                                              -0.0023      0.001     -3.314      0.001      -0.004      -0.001\n",
       "Area_NE BOISE                                                  0.0074      0.000     18.021      0.000       0.007       0.008\n",
       "Area_NE MERIDIAN                                              -0.0035      0.001     -6.666      0.000      -0.004      -0.002\n",
       "Area_NORTH BOISE                                               0.0070      0.000     18.732      0.000       0.006       0.008\n",
       "Area_NW BOISE-GARDEN CITY                                      0.0019      0.000      4.968      0.000       0.001       0.003\n",
       "Area_SE BOISE                                                  0.0029      0.000      8.055      0.000       0.002       0.004\n",
       "Area_SW BOISE                                                 -0.0003      0.000     -0.698      0.485      -0.001       0.001\n",
       "Area_SW BOISE-MERIDIAN                                      7.013e-05      0.001      0.126      0.899      -0.001       0.001\n",
       "Area_W BOISE                                                   0.0012      0.000      3.360      0.001       0.001       0.002\n",
       "Area_W BOISE-MERIDIAN                                         -0.0018      0.000     -5.046      0.000      -0.002      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                    52329.014   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           129580.490\n",
       "Skew:                           0.376   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.769   Cond. No.                     1.21e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.09e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predicted values for test set are given by:\n",
    "Note that both y_pred and y_pred2 are same. It's just these are calculated via different packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = lm2.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate R-Squared and Adjusted R-Squared Manually on Test data\n",
    "We can also calculate r-squared and adjusted r-squared via formula without using any package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value\t\t\t: 0.6775178945807676\n",
      "Adjusted R-squared value\t: 0.677447379213177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "RSS = np.sum((y_pred2 - y_test)**2)\n",
    "y_mean = np.mean(y_test)\n",
    "TSS = np.sum((y_test - y_mean)**2)\n",
    "R2 = 1 - RSS/TSS\n",
    "#R2\n",
    "\n",
    "n=X_test.shape[0]\n",
    "p=X_test.shape[1] - 1\n",
    "\n",
    "adj_rsquared = 1 - (1 - R2) * ((n - 1)/(n-p-1))\n",
    "#adj_rsquared\n",
    "\n",
    "## Added\n",
    "print(\"R-squared value\\t\\t\\t:\",R2)\n",
    "print(\"Adjusted R-squared value\\t:\",adj_rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Outliers:\n",
    "Firstly we try to get the studentized residuals using get_influence( ). The studentized residuals are saved in resid_student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = lm2.get_influence()  \n",
    "#resid_student = influence.resid_studentized_external"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code get stuck on next cell. Run on home computer and pickle then uplead from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_student = influence.resid_studentized_external"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the training set and the residuals we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resid_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = pd.concat([x_train,pd.Series(resid_student,name = \"Studentized Residuals\")],axis = 1)\n",
    "resid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the absolute value of studentized residuals is more than 3 then that observation is considered as an outlier and hence should be removed. We try to create a logical vector for the absolute studentized residuals more than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid.loc[np.absolute(resid[\"Studentized Residuals\"]) > 3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the outliers are given by ind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = resid.loc[np.absolute(resid[\"Studentized Residuals\"]) > 3,:].index\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Outlier\n",
    "Using the drop( ) function we remove the outlier from our training sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.drop(ind,axis = 0,inplace = True)\n",
    "x_train.drop(ind,axis = 0,inplace = True)  #Interept column is not there\n",
    "X_train.drop(ind,axis = 0,inplace = True)  #Intercept column is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Removing Multicollinearity\n",
    "We use the statsmodels library to calculate VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "[variance_inflation_factor(x_train.values, j) for j in range(x_train.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to remove the collinear variables. We choose a threshold of 5 which means if VIF is more than 5 for a particular variable then that variable will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(x):\n",
    "    thresh = 5.0\n",
    "    output = pd.DataFrame()\n",
    "    k = x.shape[1]\n",
    "    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n",
    "    for i in range(1,k):\n",
    "        print(\"Iteration no.\")\n",
    "        print(i)\n",
    "        print(vif)\n",
    "        a = np.argmax(vif)\n",
    "        print(\"Max VIF is for variable no.:\")\n",
    "        print(a)\n",
    "        if vif[a] <= thresh :\n",
    "            break\n",
    "        if i == 1 :          \n",
    "            output = x.drop(x.columns[a], axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "        elif i > 1 :\n",
    "            output = output.drop(output.columns[a],axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "    return(output)\n",
    "train_out = calculate_vif(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we view the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the variables from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()\n",
    "x_test.drop([\"Water\",\"CA\",\"FA\"],axis = 1,inplace = True)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running linear regression again on our new training set (without multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sma\n",
    "import statsmodels.formula.api as sm\n",
    "train_out = sma.add_constant(train_out) ## let's add an intercept (beta_0) to our model\n",
    "x_test.drop([\"Water\",\"CA\",\"FA\"],axis = 1,inplace = True)\n",
    "X_test = sma.add_constant(x_test)\n",
    "lm2 = sm.OLS(y_train,train_out).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking normality of residuals We use Shapiro Wilk test from scipy library to check the normality of residuals.\n",
    "1. Null Hypothesis: The residuals are normally distributed.\n",
    "2. Alternative Hypothesis: The residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.shapiro(lm2.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pvalue is 0.6269 (second value from above) thus at 5% level of significance we can say that the residuals are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for autocorrelation To ensure the absence of autocorrelation we use Ljungbox test.\n",
    "1. Null Hypothesis: Autocorrelation is absent.\n",
    "2. Alternative Hypothesis: Autocorrelation is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import diagnostic as diag\n",
    "diag.acorr_ljungbox(lm2.resid , lags = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since p-value is 0.1602 thus we can accept the null hypothesis and can say that autocorrelation is absent.\n",
    "\n",
    "Checking heteroscedasticity Using Goldfeld Quandt we test for heteroscedasticity.\n",
    "1. Null Hypothesis: Error terms are homoscedastic\n",
    "2. Alternative Hypothesis: Error terms are heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(lm2.resid, lm2.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The p-value is 0.539 hence we can say that the residuals have constant variance. Hence we can say that all the assumptions of our linear regression model are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
