{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHqTieKE66cd"
   },
   "source": [
    "# Raw Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO9FEfFt7RwF"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzXruhb47RiN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WaclQKQn7ALF"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "nEE8P-UV6xcP",
    "outputId": "194005e1-e857-4515-a915-f50bc58f414a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "p0jGezKu8i2q",
    "outputId": "7e9f7882-57f0-41cf-bfa8-b3073047ff3a"
   },
   "outputs": [],
   "source": [
    "#os.listdir(\"/content/drive/My Drive/Colab Notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "pf77Pfp0S_He",
    "outputId": "2f5c2b03-1bb6-44c9-eecd-4da28bc13705"
   },
   "outputs": [],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iY7F2VQ894v"
   },
   "outputs": [],
   "source": [
    "housePath = \"/content/drive/My Drive/Colab Notebooks/house_prices.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnHL_uq170kW"
   },
   "source": [
    "# Load excel data for House Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7LS7YdF65F3"
   },
   "outputs": [],
   "source": [
    "# #wb = xlrd.open_workbook(housePath)\n",
    "# #data = pd.read_excel(housePath)\n",
    "# xl = pd.ExcelFile(housePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBWSxvhkL7YT"
   },
   "source": [
    "### Extract sheets, concat sheets, and pickle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2CTI56R_rjh"
   },
   "outputs": [],
   "source": [
    "# df00 = xl.parse(\"2000\")\n",
    "# df01 = xl.parse(\"2001\")\n",
    "# df02 = xl.parse(\"2002\")\n",
    "# df03 = xl.parse(\"2003\")\n",
    "# df04 = xl.parse(\"2004\")\n",
    "# df05 = xl.parse(\"2005\")\n",
    "# df06 = xl.parse(\"2006\")\n",
    "# df07 = xl.parse(\"2007\")\n",
    "# df08 = xl.parse(\"2008\")\n",
    "# df09 = xl.parse(\"2009\")\n",
    "# df10 = xl.parse(\"2010\")\n",
    "# df11 = xl.parse(\"2011\")\n",
    "# df12 = xl.parse(\"2012\")\n",
    "# df13 = xl.parse(\"2013\")\n",
    "# df14 = xl.parse(\"2014\")\n",
    "# df15 = xl.parse(\"2015\")\n",
    "# df16 = xl.parse(\"2016\")\n",
    "# df17 = xl.parse(\"2017\")\n",
    "# df18 = xl.parse(\"2018\")\n",
    "# df19 = xl.parse(\"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3aG-HD_It6o"
   },
   "outputs": [],
   "source": [
    "# df00.to_pickle(\"df00.pkl\")\n",
    "# df01.to_pickle(\"df01.pkl\")\n",
    "# df02.to_pickle(\"df02.pkl\")\n",
    "# df03.to_pickle(\"df03.pkl\")\n",
    "# df04.to_pickle(\"df04.pkl\")\n",
    "# df05.to_pickle(\"df05.pkl\")\n",
    "# df06.to_pickle(\"df06.pkl\")\n",
    "# df07.to_pickle(\"df07.pkl\")\n",
    "# df08.to_pickle(\"df08.pkl\")\n",
    "# df09.to_pickle(\"df09.pkl\")\n",
    "# df10.to_pickle(\"df10.pkl\")\n",
    "# df11.to_pickle(\"df11.pkl\")\n",
    "# df12.to_pickle(\"df12.pkl\")\n",
    "# df13.to_pickle(\"df13.pkl\")\n",
    "# df14.to_pickle(\"df14.pkl\")\n",
    "# df15.to_pickle(\"df15.pkl\")\n",
    "# df16.to_pickle(\"df16.pkl\")\n",
    "# df17.to_pickle(\"df17.pkl\")\n",
    "# df18.to_pickle(\"df18.pkl\")\n",
    "# df19.to_pickle(\"df19.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00 = pd.read_pickle(\"./Pickle/df00.pkl\")\n",
    "df01 = pd.read_pickle(\"./Pickle/df01.pkl\")\n",
    "df02 = pd.read_pickle(\"./Pickle/df02.pkl\")\n",
    "df03 = pd.read_pickle(\"./Pickle/df03.pkl\")\n",
    "df04 = pd.read_pickle(\"./Pickle/df04.pkl\")\n",
    "df05 = pd.read_pickle(\"./Pickle/df05.pkl\")\n",
    "df06 = pd.read_pickle(\"./Pickle/df06.pkl\")\n",
    "df07 = pd.read_pickle(\"./Pickle/df07.pkl\")\n",
    "df08 = pd.read_pickle(\"./Pickle/df08.pkl\")\n",
    "df09 = pd.read_pickle(\"./Pickle/df09.pkl\")\n",
    "df10 = pd.read_pickle(\"./Pickle/df10.pkl\")\n",
    "df11 = pd.read_pickle(\"./Pickle/df11.pkl\")\n",
    "df12 = pd.read_pickle(\"./Pickle/df12.pkl\")\n",
    "df13 = pd.read_pickle(\"./Pickle/df13.pkl\")\n",
    "df14 = pd.read_pickle(\"./Pickle/df14.pkl\")\n",
    "df15 = pd.read_pickle(\"./Pickle/df15.pkl\")\n",
    "df16 = pd.read_pickle(\"./Pickle/df16.pkl\")\n",
    "df17 = pd.read_pickle(\"./Pickle/df17.pkl\")\n",
    "df18 = pd.read_pickle(\"./Pickle/df18.pkl\")\n",
    "df19 = pd.read_pickle(\"./Pickle/df19.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = [df00,df01,df02,df03,df04,df05,df06,\n",
    "         df07,df08,df09,df10,df11,df12,df13,\n",
    "         df14,df15,df16,df17,df18,df19]\n",
    "\n",
    "house = pd.concat(dfList)\n",
    "house.to_pickle('house.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean house from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARCEL</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ACREAGE</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>TOWNSHIP</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>YR BUILT</th>\n",
       "      <th>REMODEL YR</th>\n",
       "      <th>...</th>\n",
       "      <th>DECK 2 CVD</th>\n",
       "      <th>GARAGE 1 SQ FT</th>\n",
       "      <th>GARAGE 1 TYPE</th>\n",
       "      <th>GARAGE 2 SQ FT</th>\n",
       "      <th>GARAGE 2 TYPE</th>\n",
       "      <th>POOL SQ FT</th>\n",
       "      <th>TAV</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sale Date</th>\n",
       "      <th>Sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0017650020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>476</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>280</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0017650030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.165</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0017650040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.144</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0017650050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>ABBS SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>2E</td>\n",
       "      <td>21</td>\n",
       "      <td>1937</td>\n",
       "      <td>1992</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>940</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>129100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ABBS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PARCEL SUFFIX  YEAR  ACREAGE           GROUP TOWNSHIP RANGE  SECTION  \\\n",
       "0  R0017650020    NaN  2000    0.246  AARON PARK SUB       3N    1E        1   \n",
       "1  R0017650030    NaN  2000    0.165  AARON PARK SUB       3N    1E        1   \n",
       "2  R0017650040    NaN  2000    0.144  AARON PARK SUB       3N    1E        1   \n",
       "3  R0017650050    NaN  2000    0.211  AARON PARK SUB       3N    1E        1   \n",
       "4  R0027000008    NaN  2000    0.270        ABBS SUB       3N    2E       21   \n",
       "\n",
       "   YR BUILT  REMODEL YR  ... DECK 2 CVD GARAGE 1 SQ FT  GARAGE 1 TYPE  \\\n",
       "0      1998           0  ...        NaN            476       DETACHED   \n",
       "1      1999           0  ...        NaN            280       DETACHED   \n",
       "2      1999           0  ...        NaN            280       DETACHED   \n",
       "3      1998           0  ...        NaN              0            NaN   \n",
       "4      1937        1992  ...        NaN            240       DETACHED   \n",
       "\n",
       "  GARAGE 2 SQ FT  GARAGE 2 TYPE  POOL SQ FT       TAV  Sale Price  Sale Date  \\\n",
       "0            280       DETACHED           0  158000.0         NaN        NaT   \n",
       "1              0            NaN           0  165800.0         NaN        NaT   \n",
       "2              0            NaN           0  165800.0         NaN        NaT   \n",
       "3              0            NaN           0  155000.0         NaN        NaT   \n",
       "4            940       DETACHED           0  129100.0         NaN        NaT   \n",
       "\n",
       "          Sub  \n",
       "0  AARON PARK  \n",
       "1  AARON PARK  \n",
       "2  AARON PARK  \n",
       "3  AARON PARK  \n",
       "4        ABBS  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = pd.read_pickle('house.pkl')\n",
    "\n",
    "# Clean up groups to be joined with neighKey\n",
    "regList = [' SUB\\s*', ' ADD\\s*', '\\s*TO BOISE',' AMD\\s*', ' TO BOISE', '\\s*NO\\s\\d\\d']\n",
    "house['Sub'] = house['GROUP'].replace(regList,'', regex = True)\n",
    "\n",
    "# Remove houses that have TAV = $0\n",
    "house = house.loc[house['TAV'] != 0]\n",
    "\n",
    "house.to_pickle('house.pkl')\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41725, 43)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_block = house.loc[(house['TOWNSHIP'] == '3N')&(house['RANGE']=='2E')&(house['SECTION']==21)]\n",
    "#house.SECTION.unique()\n",
    "#my_block.SECTION.unique()\n",
    "my_block.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlN = pd.ExcelFile('Neighborhoods.xlsx')\n",
    "northEnd = xlN.parse('NorthEnd')\n",
    "benchD = xlN.parse('Bench-Depot')\n",
    "westE = xlN.parse('WestEnd')\n",
    "neighList = [northEnd, benchD,westE]\n",
    "neighKey = pd.concat(neighList)\n",
    "neighKey.to_pickle('neighKey.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FID               int64\n",
       "Area             object\n",
       "Neighborhood     object\n",
       "Subdivision      object\n",
       "Instrument        int64\n",
       "Subdivis_1        int64\n",
       "RecordedDa       object\n",
       "RecorderPa        int64\n",
       "InitialTax        int64\n",
       "DeveloperI        int64\n",
       "EngineerID        int64\n",
       "GroupNumbe       object\n",
       "Shape_STAr      float64\n",
       "Shape_STLe      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighKey.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Subdivision</th>\n",
       "      <th>Sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North End</td>\n",
       "      <td>North End</td>\n",
       "      <td>13TH STREET TOWNHOUSES</td>\n",
       "      <td>13TH STREET TOWNHOUSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North End</td>\n",
       "      <td>North End</td>\n",
       "      <td>A R ANDOLA ADD TO BOISE</td>\n",
       "      <td>A R ANDOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North End</td>\n",
       "      <td>North End</td>\n",
       "      <td>A R ANDOLA ADD TO BOISE AMD</td>\n",
       "      <td>A R ANDOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North End</td>\n",
       "      <td>North End</td>\n",
       "      <td>ABBIE HAGLER TRACT</td>\n",
       "      <td>ABBIE HAGLER TRACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North End</td>\n",
       "      <td>North End</td>\n",
       "      <td>ADAMS TRACT</td>\n",
       "      <td>ADAMS TRACT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area Neighborhood                  Subdivision                     Sub\n",
       "0  North End    North End       13TH STREET TOWNHOUSES  13TH STREET TOWNHOUSES\n",
       "1  North End    North End      A R ANDOLA ADD TO BOISE              A R ANDOLA\n",
       "2  North End    North End  A R ANDOLA ADD TO BOISE AMD              A R ANDOLA\n",
       "3  North End    North End           ABBIE HAGLER TRACT      ABBIE HAGLER TRACT\n",
       "4  North End    North End                  ADAMS TRACT             ADAMS TRACT"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighKey = pd.read_pickle('neighKey.pkl')\n",
    "\n",
    "neighKey = neighKey.iloc[:,1:4]\n",
    "\n",
    "regList = [' SUB\\s*', ' ADD\\s*', '\\s*TO BOISE',' AMD\\s*', ' TO BOISE', '\\s*NO\\s\\d\\d']\n",
    "neighKey['Sub'] = neighKey['Subdivision'].replace(regList,'', regex = True)\n",
    "\n",
    "neighKey.to_pickle('neighKey.pkl')\n",
    "neighKey.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join neighKey.pkl to house.pkl, to make houseAll.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARCEL</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ACREAGE</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>TOWNSHIP</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>YR BUILT</th>\n",
       "      <th>REMODEL YR</th>\n",
       "      <th>...</th>\n",
       "      <th>GARAGE 1 TYPE</th>\n",
       "      <th>GARAGE 2 SQ FT</th>\n",
       "      <th>GARAGE 2 TYPE</th>\n",
       "      <th>POOL SQ FT</th>\n",
       "      <th>TAV</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Sale Date</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Area</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0017650020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.246</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>280</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0017650030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.165</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0017650040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.144</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>165800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0017650050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>AARON PARK SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>1E</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AARON PARK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0027000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>ABBS SUB</td>\n",
       "      <td>3N</td>\n",
       "      <td>2E</td>\n",
       "      <td>21</td>\n",
       "      <td>1937</td>\n",
       "      <td>1992</td>\n",
       "      <td>...</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>940</td>\n",
       "      <td>DETACHED</td>\n",
       "      <td>0</td>\n",
       "      <td>129100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ABBS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PARCEL SUFFIX  YEAR  ACREAGE           GROUP TOWNSHIP RANGE  SECTION  \\\n",
       "0  R0017650020    NaN  2000    0.246  AARON PARK SUB       3N    1E        1   \n",
       "1  R0017650030    NaN  2000    0.165  AARON PARK SUB       3N    1E        1   \n",
       "2  R0017650040    NaN  2000    0.144  AARON PARK SUB       3N    1E        1   \n",
       "3  R0017650050    NaN  2000    0.211  AARON PARK SUB       3N    1E        1   \n",
       "4  R0027000008    NaN  2000    0.270        ABBS SUB       3N    2E       21   \n",
       "\n",
       "   YR BUILT  REMODEL YR  ... GARAGE 1 TYPE GARAGE 2 SQ FT  GARAGE 2 TYPE  \\\n",
       "0      1998           0  ...      DETACHED            280       DETACHED   \n",
       "1      1999           0  ...      DETACHED              0            NaN   \n",
       "2      1999           0  ...      DETACHED              0            NaN   \n",
       "3      1998           0  ...           NaN              0            NaN   \n",
       "4      1937        1992  ...      DETACHED            940       DETACHED   \n",
       "\n",
       "  POOL SQ FT       TAV  Sale Price  Sale Date         Sub  Area  Neighborhood  \n",
       "0          0  158000.0         NaN        NaT  AARON PARK   NaN           NaN  \n",
       "1          0  165800.0         NaN        NaT  AARON PARK   NaN           NaN  \n",
       "2          0  165800.0         NaN        NaT  AARON PARK   NaN           NaN  \n",
       "3          0  155000.0         NaN        NaT  AARON PARK   NaN           NaN  \n",
       "4          0  129100.0         NaN        NaT        ABBS   NaN           NaN  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighKey = pd.read_pickle('neighKey.pkl')\n",
    "house = pd.read_pickle('house.pkl')\n",
    "\n",
    "houseAll = pd.merge(house, neighKey, on = 'Sub', how = 'left')\n",
    "houseAll = houseAll.drop(['Subdivision'],axis = 1)\n",
    "\n",
    "houseAll.to_pickle('houseAll.pkl')\n",
    "houseAll.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357249, 45)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houseAll.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8K2tKNCT73x9"
   },
   "source": [
    "### Function to make Lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Zv8TbRfDvH_"
   },
   "outputs": [],
   "source": [
    "yearList = [\"2000\",\"2001\",\"2002\",\"2003\",\"2004\",\"2005\",\n",
    "         \"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\n",
    "         \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\n",
    "         \"2018\",\"2019\"]\n",
    "def stringList(yearList,begin,end):\n",
    "  tempList = []\n",
    "  for year in yearList:\n",
    "    tempList.append(begin+year+end)\n",
    "  return tempList\n",
    "\n",
    "\n",
    "pklList = stringList(yearList,\"df\",\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r9EauUqGCuSI",
    "outputId": "a950cb8d-8e6f-4e84-9ace-ee87467f47a0"
   },
   "outputs": [],
   "source": [
    "yearList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp8Qc5cq_LNi"
   },
   "source": [
    "# Raw Jobs Data into dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xl2 = pd.ExcelFile(\"/content/drive/My Drive/Colab Notebooks/boise_msa_jobs_2000_to_2018.xlsx\")\n",
    "xl2 = pd.ExcelFile(\"boise_msa_jobs_2000_to_2018.xlsx\")\n",
    "rawJobs = xl2.parse(\"raw\")\n",
    "rawJobs.to_pickle(\"rawJobs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From rawJobs.pkl to metro_jobs from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "PemhXp9__Low",
    "outputId": "e6f9ac62-c945-4b02-c5e4-f876b20c3757"
   },
   "outputs": [],
   "source": [
    "# open the pickle and turn it into a dataframe\n",
    "rawJobs = pd.read_pickle(\"rawJobs.pkl\")\n",
    "metroJobs = rawJobs.copy()\n",
    "\n",
    "# Splitting Strings\n",
    "metroJobs['Occ_Cat_Code'], metroJobs['Occ_Sub_Cat_Code'] = metroJobs['occ_code'].str.split('-',1).str\n",
    "\n",
    "\n",
    "# Assigning New Values\n",
    "metroJobs.loc[metroJobs.group != 'major','group'] = 0\n",
    "metroJobs.loc[metroJobs.group == 'major','group'] = 1\n",
    "\n",
    "# Assigning New Column Names\n",
    "metroJobs = metroJobs.rename(columns ={'occ_titl': 'Occ_Title', 'group':'Is_Cat_Title',\n",
    "                                        'tot_emp': 'Emp_Count', 'h_mean':'Hr_Wage_Mean',\n",
    "                                        'a_mean':'An_Wage_Mean', 'h_median': 'Hr_Median',\n",
    "                                        'a_median':'An_Median','year':'Year'})\n",
    "\n",
    "# Assigning New Data Types\n",
    "float_list = ['Emp_Count','Hr_Wage_Mean','An_Wage_Mean','Hr_Median','An_Median']\n",
    "\n",
    "# Cleaning Column Strings for Data Typing\n",
    "metroJobs[float_list] = metroJobs[float_list].replace('\\W','',regex=True)\n",
    "\n",
    "# Assigning new Data Types\n",
    "#         need to use floats becuase int cannot handle missing\n",
    "metroJobs = metroJobs.astype({'Is_Cat_Title': 'bool', 'Year':'category',\n",
    "                               'Occ_Cat_Code':'category','Occ_Sub_Cat_Code': 'category'})\n",
    "\n",
    "metroJobs[float_list] = metroJobs[float_list].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "\n",
    "# Dropped Columns\n",
    "metroJobs = metroJobs.drop(['prim_state','area','area_name','occ_code',\n",
    "                              'emp_prse','mean_prse','h_wpct10','h_wpct25',\n",
    "                             'h_wpct75','h_wpct90','a_wpct10','a_wpct25',\n",
    "                             'a_wpct75','a_wpct90'], axis = 1)\n",
    "\n",
    "# Assigning New Order to the Columns\n",
    "metroJobs = metroJobs[['Year','Occ_Cat_Code','Occ_Sub_Cat_Code','Occ_Title','Is_Cat_Title',\n",
    "                        'Emp_Count','Hr_Wage_Mean','An_Wage_Mean','Hr_Median','An_Median']]\n",
    "\n",
    "metroJobs.to_pickle('metroJobs.pkl')\n",
    "metroJobs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metroJobs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8WrEIXI9cZA"
   },
   "source": [
    "# Raw Population to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75LO9yqO_LsI"
   },
   "outputs": [],
   "source": [
    "# xl3 = pd.ExcelFile(\"/content/drive/My Drive/Colab Notebooks/idaho_county_population_2000_to_2010.xlsx\")\n",
    "# xl4 = pd.ExcelFile(\"/content/drive/My Drive/Colab Notebooks/idaho_county_population_2010_to_2018.xlsx\")\n",
    " xl3 = pd.ExcelFile(\"idaho_county_population_2000_to_2010.xlsx\")\n",
    " xl4 = pd.ExcelFile(\"idaho_county_population_2010_to_2018.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJgv8BD1_Ki_"
   },
   "outputs": [],
   "source": [
    "dfpop1 = xl3.parse(\"main\")\n",
    "dfpop1.to_pickle('rawPop1.pkl')\n",
    "dfpop2 = xl4.parse(\"main\")\n",
    "dfpop2.to_pickle('rawPop2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfpop1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUv3uNSEAkCJ"
   },
   "source": [
    "### This code to clean and prep population 00-10 from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "9d9F7b7XCVEm",
    "outputId": "ca971a40-47c9-463f-a53d-34cb224fc522"
   },
   "outputs": [],
   "source": [
    "rawPop1 = pd.read_pickle('rawPop1.pkl')\n",
    "temp1 = rawPop1.copy()\n",
    "temp1 = temp1.iloc[2:48]\n",
    "temp1 = temp1.replace(['County','\\.','\\s'],'', regex = True)\n",
    "cTemp = temp1['table with row headers in column A and column headers in rows 3 through 4 (leading dots indicate sub-parts)']\n",
    "temp1 = temp1.drop(['table with row headers in column A and column headers in rows 3 through 4 (leading dots indicate sub-parts)',\n",
    "                    'Unnamed: 1','Unnamed: 12','Unnamed: 13'], axis = 1)\n",
    "temp1 = temp1.astype(int)\n",
    "temp1.columns = temp1.iloc[0]\n",
    "temp1 = temp1.iloc[2:]\n",
    "temp1['County'] = cTemp\n",
    "pop1 = temp1.copy()\n",
    "pop1.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code to clean and prep population 10-18 from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "qLJb1fwlAbd8",
    "outputId": "8698fab0-3c36-473a-9685-0067d58c95c7"
   },
   "outputs": [],
   "source": [
    "rawPop2 = pd.read_pickle('rawPop2.pkl')\n",
    "temp2 = rawPop2.copy()\n",
    "temp2 = temp2.replace(['Population Estimate \\(as of July 1\\) \\- ','County, Idaho'],'', regex = True)\n",
    "temp2.columns = temp2.iloc[0]\n",
    "#temp2 = temp_df.iloc[2:]\n",
    "cT2 = temp2['Geography']\n",
    "temp2 = temp2.drop(['Id','Id2','Geography','April 1, 2010 - Census',\n",
    "                     'April 1, 2010 - Estimates Base'], axis = 1)\n",
    "temp2 = temp2.astype(int)\n",
    "temp2['County'] = cT2\n",
    "temp2 = temp2.iloc[1:]\n",
    "temp2 = temp2.replace('\\s','', regex = True)\n",
    "\n",
    "pop2 = temp2.copy()\n",
    "pop2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the cleaned data frames for the 00-09 pop and 10-18 pop and pickle the result (totalPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "HDRUezd4A3gB",
    "outputId": "90af4e71-7e8a-41d4-a0ed-3d2e28340c84"
   },
   "outputs": [],
   "source": [
    "totalPop = pd.merge(pop2,pop1, on = 'County')\n",
    "\n",
    "# Reorder columns, not all column titles are str some are int, going to \n",
    "# transpose df so will turn them all into factors then\n",
    "totalPop = totalPop[[\"County\",2000,2001,2002,2003,2004,2005,2006,2007,\n",
    "                    2008,2009,\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\n",
    "                    \"2016\",\"2017\",\"2018\"]]\n",
    "\n",
    "\n",
    "totalPop.to_pickle('totalPop.pkl')\n",
    "totalPop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPop = pd.read_pickle('totalPop.pkl')\n",
    "#totalPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From totalPop.pkl to metroPop, then pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPop = pd.read_pickle('totalPop.pkl')\n",
    "totalPop = totalPop.iloc[[0,7,13,22,36],:]\n",
    "\n",
    "temp3 = totalPop.copy()\n",
    "temp3 = temp3.T\n",
    "temp3.columns = temp3.iloc[0]\n",
    "temp3 = temp3.iloc[1:]\n",
    "temp3 = temp3.reset_index()\n",
    "temp3 = temp3.rename(columns={'index':'Year'})\n",
    "\n",
    "# Add the columns together for a total population\n",
    "temp3['TotalPop'] = temp3['Ada']+temp3['Boise']+temp3['Canyon']+temp3['Gem']+temp3['Owyhee']\n",
    "metroPop = temp3.copy()\n",
    "pop_year_totals = metroPop.drop(columns=['Ada','Boise','Canyon','Gem','Owyhee'])\n",
    "\n",
    "metroPop = metroPop.astype('int')\n",
    "metroPop = metroPop.astype({'Year': 'category'})\n",
    "\n",
    "metroPop.to_pickle('metroPop.pkl')\n",
    "metroPop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metroPop = pd.read_pickle('metroPop.pkl')\n",
    "metroPop.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load House excel files and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " xl5 = pd.ExcelFile(\"idaho_housing_unit_count_2000_to_2010.xlsx\")\n",
    " xl6 = pd.ExcelFile(\"idaho_housing_unit_count_2010_to_2018.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH1 = xl5.parse(\"main\")\n",
    "dfH1.to_pickle('rawHouse1.pkl') \n",
    "dfH2 = xl6.parse(\"main\")\n",
    "dfH2.to_pickle('rawHouse2.pkl')\n",
    "#dfH1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From rawHouse1.pkl clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp5 = pd.read_pickle('rawHouse1.pkl')\n",
    "temp5 = temp5.iloc[2:48]\n",
    "# temp1 = temp1.replace(['County','\\.','\\s'],'', regex = True)\n",
    "cTemp5 = temp5['table with row headers in column A and column headers in rows 3 through 4. (leading dots indicate sub-parts)']\n",
    "temp5 = temp5.drop(['table with row headers in column A and column headers in rows 3 through 4. (leading dots indicate sub-parts)',\n",
    "                    'Unnamed: 1','Unnamed: 12','Unnamed: 13'], axis = 1)\n",
    "temp5 = temp5.astype(int)\n",
    "temp5.columns = temp5.iloc[0]\n",
    "temp5 = temp5.iloc[2:]\n",
    "temp5['County'] = cTemp\n",
    "\n",
    "house1 = temp5.copy()\n",
    "house1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From rawHouse2.pkl clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp6 = pd.read_pickle('rawHouse2.pkl')\n",
    "temp6 = temp6.replace(['Housing Unit Estimate \\(as of July 1\\) \\- ','County, Idaho'],'', regex = True)\n",
    "temp6.columns = temp6.iloc[0]\n",
    "\n",
    "cT6 = temp6['Geography']\n",
    "temp6 = temp6.drop(['Id','Id2','Geography','April 1, 2010 - Census',\n",
    "                     'April 1, 2010 - Estimates Base'], axis = 1)\n",
    "temp6 = temp6.astype(int)\n",
    "temp6['County'] = cT6\n",
    "temp6 = temp6.iloc[1:]\n",
    "temp6 = temp6.replace('\\s','', regex = True)\n",
    "\n",
    "house2 = temp6.copy()\n",
    "house2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine cleaned dataframes to merge into totalHouse and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalHouse = pd.merge(house2,house1, on = 'County')\n",
    "\n",
    "# Reorder columns, not all column titles are str some are int, going to \n",
    "# transpose df so will turn them all into factors then\n",
    "totalHouse = totalHouse[[\"County\",2000,2001,2002,2003,2004,2005,2006,2007,\n",
    "                    2008,2009,\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\n",
    "                    \"2016\",\"2017\",\"2018\"]]\n",
    "# # ,\"2005\",\n",
    "# #          \"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\n",
    "# #          \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\n",
    "# #          \"2018\"]]\n",
    "totalHouse.to_pickle('totalHouse.pkl')\n",
    "totalHouse.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalHouse = pd.read_pickle('totalHouse.pkl')\n",
    "#totalHouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From totalHouse.pkl make metroHouse and pickle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metroHouseT = totalHouse.copy()\n",
    "metroHouseT = metroHouseT.iloc[[0,7,13,22,36],:]\n",
    "\n",
    "tempH = metroHouseT.copy()\n",
    "tempH = tempH.T\n",
    "tempH.columns = tempH.iloc[0]\n",
    "tempH = tempH.iloc[1:]\n",
    "tempH = tempH.reset_index()\n",
    "tempH = tempH.rename(columns={'index':'Year'})\n",
    "\n",
    "# Add columns together for a total house count\n",
    "tempH['TotalHouse'] = tempH['Ada']+tempH['Boise']+tempH['Canyon']+tempH['Gem']+tempH['Owyhee']\n",
    "\n",
    "metroHouse = tempH.copy()\n",
    "metroHouse = metroHouse.astype('int')\n",
    "metroHouse = metroHouse.astype({'Year': 'category'})\n",
    "\n",
    "\n",
    "metroHouse.to_pickle('metroHouse.pkl')\n",
    "metroHouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metroHouse = pd.read_pickle('metroHouse.pkl')\n",
    "metroHouse.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create yearTotals from metroHouse.pkl and metroPop.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metroHouse = pd.read_pickle('metroHouse.pkl')\n",
    "metroPop = pd.read_pickle('metroPop.pkl')\n",
    "yearTotals = metroHouse.copy()\n",
    "yearTotals = yearTotals.drop(['Ada','Boise','Gem','Canyon','Owyhee'],axis =1)\n",
    "yearTotals['TotalPop'] = metroPop['TotalPop']\n",
    "yearTotals.to_pickle('yearTotals.pkl')\n",
    "yearTotals"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Raw_Data_Prep.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
